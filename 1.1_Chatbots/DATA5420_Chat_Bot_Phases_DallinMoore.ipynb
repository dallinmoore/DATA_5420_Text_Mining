{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **In-Class Assignment 1: Pretrained and Deterministic Chat Bots**\n",
        "###**DATA 5420**\n",
        "\n",
        "###Name:Dallin Moore\n",
        "\n",
        "**In this  introductary assignment we will examine the pros and cons of different phases of chatbots, including determininstic, learning-based, and generative (which you will interact with separately).**\n",
        "\n",
        "**We will begin by examining some prebuilt deterministic chat-bots available through `nltk`, then I will provide a brief demonstration in building a chatbot off of conversational pairs, and you will create your own. Finally, I will demonstrate a very basic learning-based chatbot trained with a shallow neural network. You will finally choose an LLM of your choice and hold a brief conversation, then reflect on the pros and cons of each method of chatbot creation.**\n"
      ],
      "metadata": {
        "id": "D16LFCSfUVBM"
      },
      "id": "D16LFCSfUVBM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ],
      "metadata": {
        "id": "G5dDfJrUjNi6"
      },
      "id": "G5dDfJrUjNi6"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c57d69d6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections"
      ],
      "id": "c57d69d6"
    },
    {
      "cell_type": "code",
      "source": [
        "reflections"
      ],
      "metadata": {
        "id": "AT-RGCBGWBJs",
        "outputId": "6bfc1a18-ffe0-4358-daa7-6ab64ec69128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AT-RGCBGWBJs",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'i am': 'you are',\n",
              " 'i was': 'you were',\n",
              " 'i': 'you',\n",
              " \"i'm\": 'you are',\n",
              " \"i'd\": 'you would',\n",
              " \"i've\": 'you have',\n",
              " \"i'll\": 'you will',\n",
              " 'my': 'your',\n",
              " 'you are': 'I am',\n",
              " 'you were': 'I was',\n",
              " \"you've\": 'I have',\n",
              " \"you'll\": 'I will',\n",
              " 'your': 'my',\n",
              " 'yours': 'mine',\n",
              " 'you': 'me',\n",
              " 'me': 'you'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d459fc53"
      },
      "source": [
        "**Try out having a brief conversation with one these chat bots from nltk, what are their strengths and weaknesses?**"
      ],
      "id": "d459fc53"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9ee14e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "84f1e492-2605-4d85-eecf-a356fcf3b5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iesha the TeenBoT\n",
            "---------\n",
            "Talk to the program by typing in plain English, using normal upper-\n",
            "and lower-case letters and punctuation.  Enter \"quit\" when done.\n",
            "========================================================================\n",
            "hi!! i'm iesha! who r u??!\n",
            ">dallin. what r u up to?\n",
            "booooring! how old r u?\n",
            ">16\n",
            "do u watch anime? i like sailor moon! ^_^\n",
            ">no. gross.\n",
            "do u like anime?\n",
            ">no\n",
            "ur funny! kekeke\n",
            ">stop\n",
            "i wish i was a kitty!! kekekeke ^_^\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7bbd9e0ca31f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# nltk.chat.eliza_chat()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miesha_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# nltk.chat.rude.rude_chat()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# nltk.chat.zen_chat()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/chat/iesha.py\u001b[0m in \u001b[0;36miesha_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi!! i'm iesha! who r u??!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0miesha_chatbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/chat/util.py\u001b[0m in \u001b[0;36mconverse\u001b[0;34m(self, quit)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# nltk.chat.eliza_chat()\n",
        "nltk.chat.iesha_chat()\n",
        "# nltk.chat.rude.rude_chat()\n",
        "#\n",
        "nltk.chat.zen_chat()"
      ],
      "id": "9ee14e56"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strenths:**\n",
        "\n",
        "\n",
        "*   asking questions\n",
        "*   mimicking a specific style (therapist/teen/etc.)\n",
        "\n",
        "**Weaknesses:**\n",
        "\n",
        "\n",
        "\n",
        "*   answering questions\n",
        "*   using correct grammer ('how are me?')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K2lQLswWVPw5"
      },
      "id": "K2lQLswWVPw5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "853a02c3"
      },
      "source": [
        "**Now I'm going to demonstrate how I can make an extremely basic chat-bot by creating a list of statements and reponses for a determinstic chat-bot.**\n",
        "\n",
        "**These statements will use some basic *regular expressions*, we will use throughout the semester to perform text cleaning.**\n",
        "\n",
        "**Let's try some basic statements and responses for small-talk.**"
      ],
      "id": "853a02c3"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "064ce2a9"
      },
      "outputs": [],
      "source": [
        "pairs = [\n",
        "    [\n",
        "        r\"(hi|hello|howdy|howzit?)\",\n",
        "        [\"%1\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"my name is (.*)\",\n",
        "        [\"Hello %1, how are you doing today?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"good|bad|awful\",\n",
        "        [\"That's good to hear!, What can I do for you?\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"Not much. I just wanted to (.*)\",\n",
        "        [\"Great! I can %1.\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"quit\",\n",
        "        [\"See ya later alligator\"]\n",
        "    ],\n",
        "]"
      ],
      "id": "064ce2a9"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ced16d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0cf4b7-54d6-4c6e-d59b-59957b7a9f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Howdy! I'm a chatbot here to chat!\n",
            ">howzit?\n",
            "howzit\n",
            ">my name is dallin\n",
            "Hello dallin, how are you doing today?\n",
            ">awful\n",
            "That's good to hear!, What can I do for you?\n",
            ">Not much. I just wanted to chat with you\n",
            "That's good to hear!, What can I do for you?\n",
            ">Not much. I just wanted to chat with you\n",
            "That's good to hear!, What can I do for you?\n",
            ">quit\n",
            "That's good to hear!, What can I do for you?\n"
          ]
        }
      ],
      "source": [
        "def chat():\n",
        "    print(\"Howdy! I'm a chatbot here to chat!\")\n",
        "    chat = Chat(pairs, reflections)\n",
        "    chat.converse()\n",
        "#initiate the conversation\n",
        "if __name__ == \"__main__\":\n",
        "    chat()"
      ],
      "id": "ced16d9f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Now you try!**\n",
        "\n",
        "**Try creating your own pairs of statements and responses then rerun the chat function to see if you can hold a longer conversation then my very basic one.**"
      ],
      "metadata": {
        "id": "9TEvvdI-T9el"
      },
      "id": "9TEvvdI-T9el"
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    [\n",
        "        r\"(display|charging|battery|screen|camera)\",\n",
        "        [\"Oh no! I hate when the %1 doesn't work on my phone! Have you tried restarting your phone?\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"no\",\n",
        "        [\"Why don't you try that first!\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"yes\",\n",
        "        [\"That's a tough one! I don't think I'll be able to help you today.\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"it works|it's fixed\",\n",
        "        [\"Great! Looks like I solved your issue!\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"quit\",\n",
        "        [\"Thanks for letting me help you!\"]\n",
        "    ],\n",
        "]"
      ],
      "metadata": {
        "id": "e3iki3WcUMYq"
      },
      "id": "e3iki3WcUMYq",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat():\n",
        "    print(\"I'm here to help with you broken phone. What part of your phone is broken?\")\n",
        "    chat = Chat(pairs, reflections)\n",
        "    chat.converse()\n",
        "#initiate the conversation\n",
        "if __name__ == \"__main__\":\n",
        "    chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKki48_EHr2d",
        "outputId": "8fedc81b-e7c1-43bd-bf72-2d050d24d309"
      },
      "id": "IKki48_EHr2d",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm here to help with you broken phone. What part of your phone is broken?\n",
            ">battery\n",
            "Oh no! I hate when the battery doesn't work on my phone! Have you tried restarting your phone?\n",
            ">no\n",
            "Why don't you try that first!\n",
            ">it's fixed\n",
            "Great! Looks like I solved your issue!\n",
            ">quit\n",
            "Thanks for letting me help you!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then try swapping with a partner (who doesn't know the statements you programmed) and see how far your chat-bot can go before breaking down!**\n",
        "\n",
        "**How many turns could your chatbot keep up the conversation for?**"
      ],
      "metadata": {
        "id": "Gzoh8HP4YVO1"
      },
      "id": "Gzoh8HP4YVO1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further than I thought it would! the chatbot didn't prove to be very useful, but it does somewhat pointed questions that make it easy to follow and give the answers it wants."
      ],
      "metadata": {
        "id": "Dh435b3Ck59x"
      },
      "id": "Dh435b3Ck59x"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training a learning-based chatbot with a shallow neural network**\n",
        "\n",
        "**Here is a starting point of a few conversational turns, but obviously this is quite limited. Challenge yourself to expand on this list and experiment with how adding data and changing hyperparameters like epochs impacts accuracy.**\n",
        "\n",
        "Don't worry about understanding neural nets for now, the main things to play around with here would be the `conversations` and the number of `epochs`."
      ],
      "metadata": {
        "id": "CNW9v0Mn-UWX"
      },
      "id": "CNW9v0Mn-UWX"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# sample conversational pairs\n",
        "conversations = [\n",
        "    [\"hi\", \"hello\"],\n",
        "    [\"what is your name?\", \"my name is dallin\"],\n",
        "    [\"how are you?\", \"i'm doing well\"],\n",
        "    [\"good morning\", \"good morning to you too\"],\n",
        "    [\"how old are you?\", \"i'm just a program, so I don't have an age\"],\n",
        "    [\"who created you?\",\"I was developed by dallin\"],\n",
        "    [\"what's your favorite color?\",\"my favorite color is green\"]\n",
        "]\n",
        "\n",
        "# extract vocaba nd create training data\n",
        "vocab = set()\n",
        "for conv in conversations:\n",
        "  for sentence in conv:\n",
        "    vocab |= set(sentence.split())\n",
        "\n",
        "vocab = list(vocab)\n",
        "\n",
        "# create empty list for inputs (x) and outputs (y)\n",
        "X = []\n",
        "y = []\n",
        "for conv in conversations:\n",
        "  x = [0] * len(vocab)\n",
        "  for word in conv[0].split():\n",
        "    x[vocab.index(word)] = 1\n",
        "  X.append(x)\n",
        "  y.append(conv[1])\n",
        "\n",
        "# adjust y-values to be indices in the response list\n",
        "y_indices = list(range(len(y)))\n",
        "\n",
        "# set up training and test set\n",
        "X_train, X_test, y_train_indices, y_test_indices = train_test_split(X, y_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "# build shallow neural net model\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=len(vocab), activation='relu'))\n",
        "model.add(Dense(len(vocab), activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(np.array(X_train), np.array(y_train_indices), epochs=200, verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(np.array(X_test), np.array(y_test_indices), verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (acc*100))"
      ],
      "metadata": {
        "id": "ebZixv15erWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f87e6cd-5457-4dad-cf56-ee2fdda094fe"
      },
      "id": "ebZixv15erWD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.6362 - accuracy: 0.2000\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.6308 - accuracy: 0.2000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6254 - accuracy: 0.2000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6200 - accuracy: 0.2000\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6146 - accuracy: 0.2000\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.6092 - accuracy: 0.2000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.6037 - accuracy: 0.2000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.5982 - accuracy: 0.2000\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5927 - accuracy: 0.2000\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.5871 - accuracy: 0.2000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5816 - accuracy: 0.2000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.5759 - accuracy: 0.2000\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5702 - accuracy: 0.2000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.5644 - accuracy: 0.2000\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.5585 - accuracy: 0.2000\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.5526 - accuracy: 0.2000\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.5466 - accuracy: 0.2000\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.5405 - accuracy: 0.2000\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5343 - accuracy: 0.2000\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5281 - accuracy: 0.2000\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5218 - accuracy: 0.2000\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.5155 - accuracy: 0.2000\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5091 - accuracy: 0.2000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.5026 - accuracy: 0.2000\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.4960 - accuracy: 0.2000\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4894 - accuracy: 0.2000\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.4827 - accuracy: 0.2000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.4759 - accuracy: 0.2000\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4690 - accuracy: 0.4000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.4621 - accuracy: 0.4000\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4551 - accuracy: 0.4000\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4481 - accuracy: 0.4000\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.4409 - accuracy: 0.4000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.4337 - accuracy: 0.4000\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.4264 - accuracy: 0.4000\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4191 - accuracy: 0.6000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4116 - accuracy: 0.6000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.4040 - accuracy: 0.6000\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.3964 - accuracy: 0.6000\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.3887 - accuracy: 0.6000\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.3809 - accuracy: 0.6000\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.3730 - accuracy: 0.6000\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.3650 - accuracy: 0.6000\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.3569 - accuracy: 0.6000\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.3487 - accuracy: 0.6000\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.3405 - accuracy: 0.6000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.3322 - accuracy: 0.6000\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3238 - accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3153 - accuracy: 0.6000\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.3067 - accuracy: 0.6000\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2980 - accuracy: 0.6000\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.2892 - accuracy: 0.6000\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2803 - accuracy: 0.6000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2714 - accuracy: 0.6000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.2623 - accuracy: 0.6000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.2532 - accuracy: 0.6000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.2439 - accuracy: 0.6000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2346 - accuracy: 0.6000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2252 - accuracy: 0.6000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2157 - accuracy: 0.6000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2060 - accuracy: 0.6000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1962 - accuracy: 0.6000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1864 - accuracy: 0.6000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1764 - accuracy: 0.6000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1664 - accuracy: 0.6000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.1562 - accuracy: 0.6000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.1459 - accuracy: 0.6000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1356 - accuracy: 0.6000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.1251 - accuracy: 0.6000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.1146 - accuracy: 0.6000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.1039 - accuracy: 0.6000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.0932 - accuracy: 0.6000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0823 - accuracy: 0.6000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.0713 - accuracy: 0.6000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.0601 - accuracy: 0.6000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0487 - accuracy: 0.6000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.0373 - accuracy: 0.6000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0257 - accuracy: 0.6000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0140 - accuracy: 0.6000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0022 - accuracy: 0.6000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9903 - accuracy: 0.6000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9783 - accuracy: 0.6000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9662 - accuracy: 0.6000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9541 - accuracy: 0.6000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.9418 - accuracy: 0.6000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9294 - accuracy: 0.6000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9171 - accuracy: 0.6000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9047 - accuracy: 0.6000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8921 - accuracy: 0.6000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8793 - accuracy: 0.6000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.8665 - accuracy: 0.6000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.8536 - accuracy: 0.6000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8407 - accuracy: 0.6000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8277 - accuracy: 0.6000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.8146 - accuracy: 0.6000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8014 - accuracy: 0.6000\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7880 - accuracy: 0.6000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7746 - accuracy: 0.6000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7611 - accuracy: 0.6000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7475 - accuracy: 0.6000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7338 - accuracy: 0.6000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7201 - accuracy: 0.6000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7062 - accuracy: 0.6000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6923 - accuracy: 0.6000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6783 - accuracy: 0.6000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6643 - accuracy: 0.6000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6502 - accuracy: 0.6000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6360 - accuracy: 0.6000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6221 - accuracy: 0.6000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6079 - accuracy: 0.6000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5937 - accuracy: 0.6000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5794 - accuracy: 0.6000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5650 - accuracy: 0.6000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5505 - accuracy: 0.6000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5361 - accuracy: 0.6000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5216 - accuracy: 0.6000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5071 - accuracy: 0.6000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4924 - accuracy: 0.6000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4778 - accuracy: 0.6000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4632 - accuracy: 0.6000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4485 - accuracy: 0.6000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4337 - accuracy: 0.6000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4189 - accuracy: 0.6000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4041 - accuracy: 0.8000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3893 - accuracy: 0.8000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3744 - accuracy: 0.8000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3595 - accuracy: 0.8000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3446 - accuracy: 0.8000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3296 - accuracy: 0.8000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3147 - accuracy: 0.8000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2998 - accuracy: 0.8000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2848 - accuracy: 0.8000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2698 - accuracy: 0.8000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2548 - accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2399 - accuracy: 0.8000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2249 - accuracy: 0.8000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2099 - accuracy: 0.8000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1949 - accuracy: 0.8000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1799 - accuracy: 0.8000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1649 - accuracy: 0.8000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1500 - accuracy: 0.8000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1350 - accuracy: 0.8000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1201 - accuracy: 0.8000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1052 - accuracy: 0.8000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0903 - accuracy: 0.8000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0754 - accuracy: 0.8000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0605 - accuracy: 0.8000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0457 - accuracy: 0.8000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0309 - accuracy: 0.8000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0162 - accuracy: 0.8000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0015 - accuracy: 0.8000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9868 - accuracy: 0.8000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.9721 - accuracy: 0.8000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9575 - accuracy: 0.8000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9430 - accuracy: 0.8000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9285 - accuracy: 0.8000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.9140 - accuracy: 0.8000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8996 - accuracy: 0.8000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.8852 - accuracy: 0.8000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8708 - accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8566 - accuracy: 0.8000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8424 - accuracy: 0.8000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8282 - accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8141 - accuracy: 0.8000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8001 - accuracy: 0.8000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7861 - accuracy: 0.8000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7722 - accuracy: 0.8000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7584 - accuracy: 0.8000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7446 - accuracy: 0.8000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7309 - accuracy: 0.8000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7173 - accuracy: 0.8000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7037 - accuracy: 0.8000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.6902 - accuracy: 0.8000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6768 - accuracy: 0.8000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6635 - accuracy: 0.8000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6502 - accuracy: 0.8000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.6370 - accuracy: 0.8000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6238 - accuracy: 0.8000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.6108 - accuracy: 0.8000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.5979 - accuracy: 0.8000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5850 - accuracy: 0.8000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.5721 - accuracy: 0.8000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.5594 - accuracy: 0.8000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5468 - accuracy: 0.8000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5342 - accuracy: 0.8000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5217 - accuracy: 0.8000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5092 - accuracy: 0.8000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4969 - accuracy: 0.8000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4847 - accuracy: 0.8000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4725 - accuracy: 0.8000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4603 - accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4483 - accuracy: 0.8000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4363 - accuracy: 0.8000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4245 - accuracy: 0.8000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4127 - accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4010 - accuracy: 0.8000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3893 - accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3778 - accuracy: 0.8000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3663 - accuracy: 0.8000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3549 - accuracy: 0.8000\n",
            "Test Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model and vocab used to train model\n",
        "np.save('vocab.npy', vocab)\n",
        "model.save('chatbot_model.h5')"
      ],
      "metadata": {
        "id": "_f-h4WRhhMD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38d8da9-a2ca-49aa-ca1d-c91429d0a300"
      },
      "id": "_f-h4WRhhMD9",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "from keras.models import load_model\n",
        "model = load_model('chatbot_model.h5')\n",
        "\n",
        "# load vocab\n",
        "vocab = np.load('vocab.npy')\n",
        "vocab = vocab.tolist()\n",
        "\n",
        "# process user input text\n",
        "def process_user_input(text):\n",
        "  bag = [0] * len(vocab)\n",
        "  for word in text.split():\n",
        "    if word in vocab:\n",
        "      bag[vocab.index(word)] = 1\n",
        "  return np.array(bag)\n",
        "\n",
        "# decode the response back to word from the predicted index number\n",
        "def decode_response(predicted_index):\n",
        "    return y[predicted_index]\n",
        "\n",
        "# chatbot function that takes user input and return the highest probability response\n",
        "def get_bot_response(user_input):\n",
        "    input_vector = process_user_input(user_input)\n",
        "    prediction = model.predict(input_vector.reshape(1, len(input_vector)))[0]\n",
        "    predicted_index = np.argmax(prediction)\n",
        "    return decode_response(predicted_index)\n",
        "\n",
        "# Interact with bot\n",
        "print(\"Chatbot: Hi there! Ask me anything.\")\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input == \"quit\":\n",
        "    break\n",
        "\n",
        "  bot_response = get_bot_response(user_input)\n",
        "  print(\"Chatbot:\", bot_response)"
      ],
      "metadata": {
        "id": "LGHPUcw4g6kf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "ca83bf1a-e79f-4a9e-d235-0cf2f0082fc2"
      },
      "id": "LGHPUcw4g6kf",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hi there! Ask me anything.\n",
            "You: how are you?\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Chatbot: i'm just a program, so I don't have an age\n",
            "You: how are you doing today?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Chatbot: i'm just a program, so I don't have an age\n",
            "You: what is you name\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: good morning to you too\n",
            "You: good morning\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Chatbot: good morning to you too\n",
            "You: who created you\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Chatbot: good morning to you too\n",
            "You: what is your favorite color?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: my favorite color is green\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-86d90642af57>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot: Hi there! Ask me anything.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How did your learning-based chatbot compare to your deterministic chatbot? What are the pros and cons of each approach?**"
      ],
      "metadata": {
        "id": "n40VPJ2DkJ8y"
      },
      "id": "n40VPJ2DkJ8y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It was actually worse. Getting the chatbot enough data is difficult. I was not able to come up with enough data that the chatbot could be accurate."
      ],
      "metadata": {
        "id": "bVvdMOYhkUAO"
      },
      "id": "bVvdMOYhkUAO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now navigate to the LLM of your choice, and hold a brief conversation. How does it compare, and what are some factors you think may contribute to this difference in performance?**"
      ],
      "metadata": {
        "id": "asaSs2b2kUaC"
      },
      "id": "asaSs2b2kUaC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The way that the LLM is vastly different from the chatbot. With the chatbot every scenario must be thought out and accounted for, but with the LLM I can ask it tough questions that it may have never heard before and it will still have a useful answer. The large dataset definitely helps; if our chatbots had bigger dataset of Qs and As they would also perform better, but what sets the LLM apart is being able to construct language that it thinks I want to hear."
      ],
      "metadata": {
        "id": "cQkYTEEYkhWJ"
      },
      "id": "cQkYTEEYkhWJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qzZVuV0DKbS9"
      },
      "id": "qzZVuV0DKbS9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}